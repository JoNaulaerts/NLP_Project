# ML Learning Assistant Environment Configuration
# 
# For LOCAL development: Use these settings
# For DOCKER deployment: These are overridden by docker-compose.yml

ACTIVE_LLM_PROVIDER=ollama
# ===========================================
# LLM Provider Selection
# ===========================================
# Options: groq, cerebras, ollama
# groq = Fast & Free (has rate limits)
# cerebras = Higher rate limits
# ollama = Local (no rate limits, requires local installation)
SAMPLE_PDF_PATH="./Abdul_Salam_CV.pdf"
# ==================== DOCKER MCP GATEWAY ====================
MCP_GATEWAY_URL=http://localhost:3000
USE_DOCKER_MCP=true
# ===========================================
# Groq Configuration (Cloud - Fast & Free)
# Get your API key at: https://console.groq.com
# ===========================================
GROQ_API_KEY=API_KEY_HERE
GROQ_MODEL_NAME=llama-3.1-8b-instant


# ===========================================
# Cerebras Configuration (Cloud - Fallback, 10x higher rate limits)
# Get your free API key at: https://cloud.cerebras.ai/
# Key should start with "csk-" 
# ===========================================
CEREBRAS_API_KEY=API_KEY_HERE
CEREBRAS_MODEL_NAME=llama3.1-8b


# ===========================================
# Web Search API (Tavily - AI-optimized search)
# Get your free API key at: https://tavily.com
# ===========================================
TAVILY_API_KEY=API_KEY_HERE


# ===========================================
# Ollama Configuration (Local - Last resort fallback)
# Download Ollama from: https://ollama.com
# After install, run: ollama pull llama3.1:8b
# ===========================================
# LLM (remote)
OLLAMA_HOST_MODE=remote
OLLAMA_REMOTE_URL=http://192.168.0.116:11434
OLLAMA_MODEL_NAME=qwen2.5:14b-instruct

# Embeddings (local)
OLLAMA_EMBEDDINGS_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=mxbai-embed-large

# ===========================================
# Memory & Storage Configuration
# ===========================================
# CrewAI Memory Storage Directory (for long-term memory)
OLLAMA_EMBEDDING_MODEL=mxbai-embed-large
CREWAI_STORAGE_DIR=./data/crewai_memory
CREWAI_TELEMETRY=false

# ChromaDB Path (for RAG document storage)
CHROMA_DB_PATH=./data/chroma_db

# ==================== CHROMADB (RAG Vector Store) ====================
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_COLLECTION=ml_materials



# ===========================================
# Application Settings
# ===========================================
# Debug & Telemetry
DEBUG_MODE=true
CREWAI_TRACING_ENABLED=false

# File Upload Limits
MAX_UPLOAD_SIZE_MB=10
